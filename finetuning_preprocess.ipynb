{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbfc8e1f",
   "metadata": {},
   "source": [
    "code to match input data with student traffic reports for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fe3a539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['2022', '2023', '2024'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading multiple sheets from Excel file with input data\n",
    "sheets_dict = pd.read_excel('./RTVSlo/Podatki - PrometnoPorocilo_2022_2023_2024.xlsx', engine=\"openpyxl\", sheet_name=None)\n",
    "print(sheets_dict.keys()) #prints keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f678717f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LegacyId', 'Datum', 'Operater', 'A1', 'B1', 'C1', 'A2', 'B2', 'C2',\n",
      "       'TitlePomembnoSLO', 'ContentPomembnoSLO', 'TitleNesreceSLO',\n",
      "       'ContentNesreceSLO', 'TitleZastojiSLO', 'ContentZastojiSLO',\n",
      "       'TitleVremeSLO', 'ContentVremeSLO', 'TitleOvireSLO', 'ContentOvireSLO',\n",
      "       'TitleDeloNaCestiSLO', 'ContentDeloNaCestiSLO', 'TitleOpozorilaSLO',\n",
      "       'ContentOpozorilaSLO', 'TitleMednarodneInformacijeSLO',\n",
      "       'ContentMednarodneInformacijeSLO', 'TitleSplosnoSLO',\n",
      "       'ContentSplosnoSLO'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Accessing a specific sheet by name\n",
    "sheet2022 = sheets_dict['2022'] # pandas dataframe\n",
    "sheet2023 = sheets_dict['2023']\n",
    "sheet2024 = sheets_dict['2024']\n",
    "\n",
    "print(sheet2022.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4f44079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LegacyId', 'Datum', 'Operater', 'A1', 'B1', 'A2', 'B2', 'C2',\n",
      "       'TitlePomembnoSLO', 'ContentPomembnoSLO', 'TitleNesreceSLO',\n",
      "       'ContentNesreceSLO', 'TitleZastojiSLO', 'ContentZastojiSLO',\n",
      "       'TitleVremeSLO', 'ContentVremeSLO', 'TitleOvireSLO', 'ContentOvireSLO',\n",
      "       'TitleDeloNaCestiSLO', 'ContentDeloNaCestiSLO', 'TitleOpozorilaSLO',\n",
      "       'ContentOpozorilaSLO', 'TitleMednarodneInformacijeSLO',\n",
      "       'ContentMednarodneInformacijeSLO', 'TitleSplosnoSLO',\n",
      "       'ContentSplosnoSLO'],\n",
      "      dtype='object')\n",
      "Index(['LegacyId', 'Datum', 'Operater', 'A1', 'B1', 'B2', 'C2',\n",
      "       'TitlePomembnoSLO', 'ContentPomembnoSLO', 'TitleNesreceSLO',\n",
      "       'ContentNesreceSLO', 'TitleZastojiSLO', 'ContentZastojiSLO',\n",
      "       'TitleVremeSLO', 'ContentVremeSLO', 'TitleOvireSLO', 'ContentOvireSLO',\n",
      "       'TitleDeloNaCestiSLO', 'ContentDeloNaCestiSLO', 'TitleOpozorilaSLO',\n",
      "       'ContentOpozorilaSLO', 'TitleMednarodneInformacijeSLO',\n",
      "       'ContentMednarodneInformacijeSLO', 'TitleSplosnoSLO',\n",
      "       'ContentSplosnoSLO'],\n",
      "      dtype='object')\n",
      "Index(['LegacyId', 'Datum', 'Operater', 'A1', 'B1', 'C2', 'ContentPomembnoSLO',\n",
      "       'ContentNesreceSLO', 'TitleZastojiSLO', 'ContentZastojiSLO',\n",
      "       'TitleVremeSLO', 'ContentVremeSLO', 'TitleOvireSLO', 'ContentOvireSLO',\n",
      "       'TitleDeloNaCestiSLO', 'ContentDeloNaCestiSLO', 'TitleOpozorilaSLO',\n",
      "       'ContentOpozorilaSLO', 'TitleMednarodneInformacijeSLO',\n",
      "       'ContentMednarodneInformacijeSLO', 'TitleSplosnoSLO',\n",
      "       'ContentSplosnoSLO'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to remove HTML tags\n",
    "def remove_html_tags(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'<[^>]*>', '', text)\n",
    "    return text\n",
    "\n",
    "# Process the data\n",
    "def process_input_data(data):\n",
    "    processed_data = []\n",
    "    for index, row in data.iterrows():\n",
    "        item = {}\n",
    "        for column in data.columns:\n",
    "            value = row[column]\n",
    "            if pd.notna(value):  # Check if the cell is not empty\n",
    "                item[column] = remove_html_tags(value)\n",
    "        processed_data.append(item)\n",
    "\n",
    "    processed_df = pd.DataFrame(processed_data)\n",
    "    processed_df = processed_df.reindex(columns=data.columns, fill_value=None) # keep the order of columns\n",
    "    processed_df = processed_df.dropna(axis=1, how='all')  # Drop columns that are completely empty\n",
    "    processed_df = processed_df.dropna(axis=0, how='all')  # Drop rows that are completely empty\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# Process each sheet\n",
    "processed_data_2022 = process_input_data(sheet2022)\n",
    "print(processed_data_2022.columns)\n",
    "processed_data_2023 = process_input_data(sheet2023)\n",
    "print(processed_data_2023.columns)\n",
    "processed_data_2024 = process_input_data(sheet2024)\n",
    "print(processed_data_2024.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfa5044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data to CSV files\n",
    "processed_data_2022.to_csv('./Processed/processed_input_2022.csv', index=False, encoding='utf-8-sig')\n",
    "processed_data_2023.to_csv('./Processed/processed_input_2023.csv', index=False, encoding='utf-8-sig')\n",
    "processed_data_2024.to_csv('./Processed/processed_input_2024.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "157c78f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FilePath', 'Datetime', 'Content'], dtype='object')\n",
      "8259\n",
      "                                            FilePath            Datetime  \\\n",
      "0  ./RTVSlo/Podatki - rtvslo.si/Promet 2022/Janua... 2022-01-01 06:00:00   \n",
      "1  ./RTVSlo/Podatki - rtvslo.si/Promet 2022/Janua... 2022-01-01 06:30:00   \n",
      "2  ./RTVSlo/Podatki - rtvslo.si/Promet 2022/Janua... 2022-01-01 07:00:00   \n",
      "3  ./RTVSlo/Podatki - rtvslo.si/Promet 2022/Janua... 2022-01-01 08:00:00   \n",
      "4  ./RTVSlo/Podatki - rtvslo.si/Promet 2022/Janua... 2022-01-01 08:30:00   \n",
      "\n",
      "                                             Content  \n",
      "0  Prometne informacije       01. 01. 2022  \\t   ...  \n",
      "1  Prometne informacije       01. 01. 2022  \\t   ...  \n",
      "2  Prometne informacije       01. 01. 2022  \\t   ...  \n",
      "3  Prometne informacije       01. 01. 2022  \\t   ...  \n",
      "4  Prometne informacije       01. 01. 2022  \\t   ...  \n",
      "9004\n",
      "                                               FilePath            Datetime  \\\n",
      "8259  ./RTVSlo/Podatki - rtvslo.si/Promet 2023/Janua... 2023-01-14 06:00:00   \n",
      "8260  ./RTVSlo/Podatki - rtvslo.si/Promet 2023/Janua... 2023-01-14 06:00:00   \n",
      "8261  ./RTVSlo/Podatki - rtvslo.si/Promet 2023/Janua... 2023-01-14 06:30:00   \n",
      "8262  ./RTVSlo/Podatki - rtvslo.si/Promet 2023/Janua... 2023-01-14 07:00:00   \n",
      "8263  ./RTVSlo/Podatki - rtvslo.si/Promet 2023/Janua... 2023-01-14 07:00:00   \n",
      "\n",
      "                                                Content  \n",
      "8259  Prometne informacije   \\t   14. 01. 2023      ...  \n",
      "8260  NOVE Prometne informacije   \\t   14. 01. 2023 ...  \n",
      "8261  Prometne informacije   \\t   14. 01. 2023      ...  \n",
      "8262  Prometne informacije   \\t   14. 01. 2023      ...  \n",
      "8263  NOVE Prometne informacije   \\t   14. 01. 2023 ...  \n",
      "2618\n",
      "                                                FilePath            Datetime  \\\n",
      "17263  ./RTVSlo/Podatki - rtvslo.si/Promet 2024/Janua... 2024-01-01 06:00:00   \n",
      "17264  ./RTVSlo/Podatki - rtvslo.si/Promet 2024/Janua... 2024-01-01 06:30:00   \n",
      "17265  ./RTVSlo/Podatki - rtvslo.si/Promet 2024/Janua... 2024-01-01 07:00:00   \n",
      "17266  ./RTVSlo/Podatki - rtvslo.si/Promet 2024/Janua... 2024-01-01 08:00:00   \n",
      "17267  ./RTVSlo/Podatki - rtvslo.si/Promet 2024/Janua... 2024-01-01 09:00:00   \n",
      "\n",
      "                                                 Content  \n",
      "17263  Prometne informacije        01. 01. 2024      ...  \n",
      "17264  Prometne informacije        01. 01. 2024      ...  \n",
      "17265  Prometne informacije        01. 01. 2024      ...  \n",
      "17266  Prometne informacije        01. 01. 2024      ...  \n",
      "17267  Prometne informacije        01. 01. 2024      ...  \n"
     ]
    }
   ],
   "source": [
    "# read from csv output data\n",
    "rtf_data = pd.read_csv('./Processed/rtf_content_sorted.csv', encoding='utf-8-sig')\n",
    "print(rtf_data.columns) # Index(['FilePath', 'Datetime', 'Content'], dtype='object')\n",
    "# convert column Datetime to datetime\n",
    "rtf_data['Datetime'] = pd.to_datetime(rtf_data['Datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "# separate by year\n",
    "rtf_data_2022 = rtf_data[rtf_data['Datetime'].dt.year == 2022]\n",
    "rtf_data_2023 = rtf_data[rtf_data['Datetime'].dt.year == 2023]\n",
    "rtf_data_2024 = rtf_data[rtf_data['Datetime'].dt.year == 2024]\n",
    "# print the number of rows and first 5 rows\n",
    "print(rtf_data_2022.shape[0])\n",
    "print(rtf_data_2022.head())\n",
    "print(rtf_data_2023.shape[0])\n",
    "print(rtf_data_2023.head())\n",
    "print(rtf_data_2024.shape[0])\n",
    "print(rtf_data_2024.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ff30f",
   "metadata": {},
   "source": [
    "create json file for each year with following structure:\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"input\": [\n",
    "            {\n",
    "                \"LegacyId\": \"...\",\n",
    "                \"Datum\": \"...\",\n",
    "                \"Operater\": \"...\",\n",
    "                \"A1\": \"...\",\n",
    "                \"B1\": \"...\",\n",
    "                \"A2\": \"...\",\n",
    "                \"B2\": \"...\",\n",
    "                \"C2\": \"...\",\n",
    "                \"TitlePomembnoSLO\": \"...\",\n",
    "                \"ContentPomembnoSLO\": \"...\",\n",
    "                \"TitleNesreceSLO\": \"...\",\n",
    "                \"ContentNesreceSLO\": \"...\",\n",
    "                \"TitleZastojiSLO\": \"...\",\n",
    "                \"ContentZastojiSLO\": \"...\",\n",
    "                \"TitleVremeSLO\": \"...\",\n",
    "                \"ContentVremeSLO\": \"...\",\n",
    "                \"TitleOvireSLO\": \"...\",\n",
    "                \"ContentOvireSLO\": \"...\",\n",
    "                \"TitleDeloNaCestiSLO\": \"...\",\n",
    "                \"ContentDeloNaCestiSLO\": \"...\",\n",
    "                \"TitleOpozorilaSLO\": \"...\",\n",
    "                \"ContentOpozorilaSLO\": \"...\",\n",
    "                \"TitleMednarodneInformacijeSLO\": \"...\",\n",
    "                \"ContentMednarodneInformacijeSLO\": \"...\",\n",
    "                \"TitleSplosnoSLO\": \"...\",\n",
    "                \"ContentSplosnoSLO\": \"...\"\n",
    "            }, ...\n",
    "        ]\n",
    "        \"output\": {\n",
    "            \"FilePath\": \".\\/RTVSlo\\/Podatki - rtvslo.si\\/Promet ...\",\n",
    "            \"Datetime\": \"...\",\n",
    "            \"Content\": \"...\",\n",
    "            \"TitleCategory\": \"...\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89654979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create json file for each year with \"input\" from processed data and \"output\" from rtf data\n",
    "# each rtf data row will be matched with the processed data rows from one hour to the time of rtf data\n",
    "def create_json_file(year, rtf_data, processed_data, time_section_in_hours):\n",
    "    json_data = []\n",
    "    processed_data['Datum'] = pd.to_datetime(processed_data['Datum'], format='%Y-%m-%d %H:%M:%S')\n",
    "    rtf_data['Datetime'] = pd.to_datetime(rtf_data['Datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    for index_rtf, row_rtf in rtf_data.iterrows():\n",
    "        item = {}\n",
    "        row_rtf_copy = row_rtf.copy()\n",
    "        # change Datetime to string to put in json\n",
    "        row_rtf_copy['Datetime'] = row_rtf_copy['Datetime'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "        item['output'] = row_rtf_copy.to_dict()\n",
    "        item['input'] = []\n",
    "        # get the datetime of the rtf data\n",
    "        datetime = row_rtf['Datetime']\n",
    "        # get the processed data rows that are within one hour of the rtf data\n",
    "        start_time = datetime - pd.Timedelta(hours=time_section_in_hours)\n",
    "        end_time = datetime\n",
    "        # change Datum to datetime\n",
    "        \n",
    "        filtered_data = processed_data[(processed_data['Datum'] >= start_time) & (processed_data['Datum'] <= end_time)]\n",
    "        for index, row in filtered_data.iterrows():\n",
    "            # change Datetime and Datum to string\n",
    "            row_copy = row.copy()\n",
    "            row_copy['Datum'] = pd.to_datetime(row_copy['Datum'], format='%Y-%m-%d %H:%M:%S')\n",
    "            row_copy['Datum'] = row_copy['Datum'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "            # add only non-empty values to the json\n",
    "            row_dict = row_copy.to_dict()\n",
    "            row_dict = {k: v for k, v in row_dict.items() if pd.notna(v)}\n",
    "            item['input'].append(row_dict)\n",
    "        json_data.append(item)\n",
    "    \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eccdaf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82829/2149222538.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rtf_data['Datetime'] = pd.to_datetime(rtf_data['Datetime'], format='%Y-%m-%d %H:%M:%S')\n",
      "/tmp/ipykernel_82829/2149222538.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rtf_data['Datetime'] = pd.to_datetime(rtf_data['Datetime'], format='%Y-%m-%d %H:%M:%S')\n",
      "/tmp/ipykernel_82829/2149222538.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rtf_data['Datetime'] = pd.to_datetime(rtf_data['Datetime'], format='%Y-%m-%d %H:%M:%S')\n"
     ]
    }
   ],
   "source": [
    "# create json file and save it\n",
    "import json\n",
    "def save_json_file(year, json_data):\n",
    "    with open(f'./Processed/input_output_all_data_{year}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# create json file for each year\n",
    "json_data_2022 = create_json_file(2022, rtf_data_2022, processed_data_2022, 1)\n",
    "save_json_file(2022, json_data_2022)\n",
    "json_data_2023 = create_json_file(2023, rtf_data_2023, processed_data_2023, 1)\n",
    "save_json_file(2023, json_data_2023)\n",
    "json_data_2024 = create_json_file(2024, rtf_data_2024, processed_data_2024, 1)\n",
    "save_json_file(2024, json_data_2024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
